{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_AutoEncoder_MNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipayandas97/Keras_Notebook/blob/master/CNN_AutoEncoder_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDjl2L6L0ZyB",
        "colab_type": "code",
        "outputId": "033f6fc0-b748-4b4a-ede9-27c394926b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_2S8VGD1E4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "2c41ac69-4f2f-47a4-a96b-d3bf16b4949c"
      },
      "source": [
        "encoding_dim = 2\n",
        "\n",
        "input_img = Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(16, (3,3), activation = 'relu', padding = 'same')(input_img)\n",
        "x = MaxPooling2D((2,2), padding = 'same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0824 17:22:24.995858 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0824 17:22:25.048458 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0824 17:22:25.059408 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0824 17:22:25.113021 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0824 17:22:25.161007 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0824 17:22:25.215905 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0824 17:22:25.232977 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0824 17:22:25.240822 140048540616576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utDNbblMSn1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f47f202-4e68-4c46-aa19-0d773309feb5"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgteyUiz2kR5",
        "colab_type": "code",
        "outputId": "4c2b714c-a920-4efa-856b-cee8159b0499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0824 17:22:27.273005 140048540616576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 84s 1ms/step - loss: 0.2381 - val_loss: 0.1843\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1736 - val_loss: 0.1691\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 84s 1ms/step - loss: 0.1586 - val_loss: 0.1559\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.1506 - val_loss: 0.1495\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 84s 1ms/step - loss: 0.1466 - val_loss: 0.1382\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.1451 - val_loss: 0.1489\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.1419 - val_loss: 0.1434\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 84s 1ms/step - loss: 0.1401 - val_loss: 0.1351\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1377 - val_loss: 0.1325\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1361 - val_loss: 0.1348\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1352 - val_loss: 0.1388\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1348 - val_loss: 0.1349\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.1338 - val_loss: 0.1324\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1334 - val_loss: 0.1253\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1334 - val_loss: 0.1408\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1326 - val_loss: 0.1237\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.1318 - val_loss: 0.1304\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.1315 - val_loss: 0.1308\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1311 - val_loss: 0.1328\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1348 - val_loss: 0.1281\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1334 - val_loss: 0.1322\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1338 - val_loss: 0.1240\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1323 - val_loss: 0.1280\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1327 - val_loss: 0.1255\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1321 - val_loss: 0.1337\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1318 - val_loss: 0.1346\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1314 - val_loss: 0.1342\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1312 - val_loss: 0.1411\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1318 - val_loss: 0.1330\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1313 - val_loss: 0.1266\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1299 - val_loss: 0.1319\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1313 - val_loss: 0.1368\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1341 - val_loss: 0.1389\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1346 - val_loss: 0.1389\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1326 - val_loss: 0.1290\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1314 - val_loss: 0.1338\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1316 - val_loss: 0.1261\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1307 - val_loss: 0.1363\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1310 - val_loss: 0.1349\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1311 - val_loss: 0.1268\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1311 - val_loss: 0.1188\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1316 - val_loss: 0.1437\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1333 - val_loss: 0.1376\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1370 - val_loss: 0.1235\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.1339 - val_loss: 0.1214\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1319 - val_loss: 0.1250\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1313 - val_loss: 0.1378\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1352 - val_loss: 0.1276\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1328 - val_loss: 0.1355\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.1335 - val_loss: 0.1350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f73e76780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C7spheCEYEr",
        "colab_type": "code",
        "outputId": "a6de8119-22ba-4840-eb75-5ec1c4d8bb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "autoencoder.layers[6].input_shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 7, 7, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEGgP6H96oB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "677c52b9-15ff-4610-e518-ed909861f7bc"
      },
      "source": [
        "p = autoencoder.predict(x_test)\n",
        "\n",
        "plt.imshow(p[1000].reshape(28,28))\n",
        "plt.gray()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUyG84Ub-WDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}